{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b17f3a-fc40-43d2-b026-798f26014493",
   "metadata": {},
   "source": [
    "# <center> News Classification with NLP and Neural Networks </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb09f44-33f4-4938-aaa4-65c3df93b527",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a1634b-c53c-4c99-8e6e-f7759bd2856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objects as go\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a02e18-a47b-4179-9c28-fb2bb93cc5d6",
   "metadata": {},
   "source": [
    "### Data\n",
    "- Import JSON file\n",
    "- Limit to top categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ebb1ae-25d6-43d9-9510-54dd2e864b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86160, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21734</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>News Roundup for July 12, 2017</td>\n",
       "      <td>Outspeak, ContributorOutspeak™ is the opinion ...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/news-roun...</td>\n",
       "      <td>But his emails. 1. The saga of the health care...</td>\n",
       "      <td>2017-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174026</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>Do You Need A Suncation?</td>\n",
       "      <td>Vanessa Van Edwards , Contributor\\nModern-day ...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/do-you-ne...</td>\n",
       "      <td>After the torment of Hurricane Sandy and the l...</td>\n",
       "      <td>2012-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143670</th>\n",
       "      <td>STYLE &amp; BEAUTY</td>\n",
       "      <td>Whitney Thompson Of 'Top Model' Fame Lands Plu...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.huffingtonpost.com/entry/whitney-t...</td>\n",
       "      <td>More plus-size role models: Last we heard from...</td>\n",
       "      <td>2013-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123426</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>3 Ways to Make Your Trip Gay -- Even If You're...</td>\n",
       "      <td>Mark Chesnut, ContributorFounder and editor, L...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/3-ways-to...</td>\n",
       "      <td></td>\n",
       "      <td>2014-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67854</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Bernie Sanders Rocks Out With Vampire Weekend ...</td>\n",
       "      <td>Kim Bellware</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/bernie-sa...</td>\n",
       "      <td>The song is actually part of the Democratic pr...</td>\n",
       "      <td>2016-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category                                           headline  \\\n",
       "21734         POLITICS                     News Roundup for July 12, 2017   \n",
       "174026          TRAVEL                           Do You Need A Suncation?   \n",
       "143670  STYLE & BEAUTY  Whitney Thompson Of 'Top Model' Fame Lands Plu...   \n",
       "123426          TRAVEL  3 Ways to Make Your Trip Gay -- Even If You're...   \n",
       "67854         POLITICS  Bernie Sanders Rocks Out With Vampire Weekend ...   \n",
       "\n",
       "                                                  authors  \\\n",
       "21734   Outspeak, ContributorOutspeak™ is the opinion ...   \n",
       "174026  Vanessa Van Edwards , Contributor\\nModern-day ...   \n",
       "143670                                                      \n",
       "123426  Mark Chesnut, ContributorFounder and editor, L...   \n",
       "67854                                        Kim Bellware   \n",
       "\n",
       "                                                     link  \\\n",
       "21734   https://www.huffingtonpost.com/entry/news-roun...   \n",
       "174026  https://www.huffingtonpost.com/entry/do-you-ne...   \n",
       "143670  https://www.huffingtonpost.com/entry/whitney-t...   \n",
       "123426  https://www.huffingtonpost.com/entry/3-ways-to...   \n",
       "67854   https://www.huffingtonpost.com/entry/bernie-sa...   \n",
       "\n",
       "                                        short_description       date  \n",
       "21734   But his emails. 1. The saga of the health care... 2017-07-12  \n",
       "174026  After the torment of Hurricane Sandy and the l... 2012-11-12  \n",
       "143670  More plus-size role models: Last we heard from... 2013-09-30  \n",
       "123426                                                    2014-05-07  \n",
       "67854   The song is actually part of the Democratic pr... 2016-01-31  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in json file to DataFrame\n",
    "df = pd.read_json('News_Category_Dataset_v2.json', lines=True)\n",
    "\n",
    "# Get the top categories by article count\n",
    "top_5_categories = df['category'].value_counts()[:5].index\n",
    "\n",
    "# Limit the DateFrame to the top categories\n",
    "df = df[df['category'].isin(top_5_categories)]\n",
    "\n",
    "# View Results\n",
    "print(df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd82dfc-6153-4f97-ad75-9007960b828b",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca86a7-4e67-4e77-839e-0a2ffbc6920f",
   "metadata": {},
   "source": [
    "#### Check data types"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e41005e-96ba-4cc5-b7e5-78f99bceae05",
   "metadata": {},
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314368a0-6cfb-4d84-8e6a-53b17873c0f8",
   "metadata": {},
   "source": [
    "#### Check NaNs "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a6edbf1-c01f-4b57-a18d-5e58be8a9fb7",
   "metadata": {},
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601100b7-6574-403b-9df5-b7009c95b3af",
   "metadata": {},
   "source": [
    "#### Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee4a10b-d5c2-4811-b945-5ebd596a25c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 duplicated rows\n",
      "There are now 0 duplicated rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df.duplicated().sum()} duplicated rows\")\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f\"There are now {df.duplicated().sum()} duplicated rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113bb9ac-6a5a-4abc-ae61-82cc5e5282f2",
   "metadata": {},
   "source": [
    "### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf4a424-ddae-4093-af0a-7b42ce4e2952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba9ece-1396-4aaf-b4fe-248728420b19",
   "metadata": {},
   "source": [
    "#### Authors \n",
    "- The `authors` field is a list containing:\n",
    "    - Name(s)\n",
    "    - Titles\n",
    "    - Organizations\n",
    "    - Misc comments\n",
    "- It also contains many NaNs in the form of empty strings\n",
    "- Approach:\n",
    "    - Replace NaNs with 'unknown'\n",
    "    - Extract author names from the field, create new field named `author_names` to be used as a bigram\n",
    "    - Leave the rest of the information in a new field named `author_notes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546711d-3f03-4745-b91c-4eb5ca22438b",
   "metadata": {},
   "source": [
    "### Author Names\n",
    "- Replace missing\n",
    "- Get Names\n",
    "- Clean non-name details\n",
    "- Cast as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f923fa-b7e9-41ea-99b3-1fa83c25f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing authors with 'unknown'\n",
    "df['authors'] = df['authors'].apply(lambda x: x.replace('','unknown') if x == '' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bf3c68-2ec9-4b35-b9f8-e3ada87814cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get author names from list\n",
    "# Split, get first, title(), split \n",
    "df['author_names'] = df['authors'].apply(lambda x: x.replace('By','').strip().split(',')[0].lower().split(' And '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab5ee91-0e6f-4884-8e8b-351fa63bba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the rest of the authors field without the names into a new field\n",
    "df['author_notes'] = df['authors'].apply(lambda x: ''.join(x.replace('By','').replace('\\n','').replace('Contributor','Contributor ').strip().split(',')[1:]).strip())\n",
    "\n",
    "# Type cast from list to string\n",
    "df['author_notes'] = df['author_notes'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85739996-443e-4d95-8cbc-5eb9ff0cc15c",
   "metadata": {},
   "source": [
    "### Links\n",
    "- The links are not helpful in their current form, need to extract keyworks from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8dd769-3f83-488f-a04e-8b86eab29beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122221                            what the media miss about\n",
       "194966                fashionably late style news this week\n",
       "10064     franken to address senate amid groping and for...\n",
       "186692                            a supposedly fun thing th\n",
       "116609                            miles teller cant find th\n",
       "Name: link_keywords, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace charaters we want to split on with commas, then split, only get the relevant entries from the resulting list\n",
    "df['link_keywords'] = df['link'].apply(lambda x: x.replace('-',',').replace(\"_\",',').replace(\"entry/\",',').split(',')[1:-2])\n",
    "\n",
    "# Typecast from list to string\n",
    "df['link_keywords'] = df['link_keywords'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# View Sample\n",
    "df['link_keywords'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ff202-4315-4e44-bd04-707dd47962df",
   "metadata": {},
   "source": [
    "### Join all text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77df868d-a8fb-49d2-962d-3ff44d3c11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['headline'] + ' ' + df['short_description'] + ' ' + df['link_keywords'] + ' ' + df['author_names'].astype(str) + ' ' + df['author_notes'] + ' ' + df['date'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6ea61-e042-41bd-8c32-79609de50c10",
   "metadata": {},
   "source": [
    "### Drop unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02ba9bb9-a3b4-4265-b6ed-8871b2cbfbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86575</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Obama Honors Military Families, Cheers On Team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191849</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>Alaska Airlines Flight Attendants Say New Unif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Billy Bush Reveals Why He Didn’t Shut Down Don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29278</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jay Pharoah Says 'Saturday Night Live' Cast Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37652</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Bella Thorne Says She Received Death Threats A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                               text\n",
       "86575        POLITICS  Obama Honors Military Families, Cheers On Team...\n",
       "191849         TRAVEL  Alaska Airlines Flight Attendants Say New Unif...\n",
       "3782    ENTERTAINMENT  Billy Bush Reveals Why He Didn’t Shut Down Don...\n",
       "29278   ENTERTAINMENT  Jay Pharoah Says 'Saturday Night Live' Cast Me...\n",
       "37652   ENTERTAINMENT  Bella Thorne Says She Received Death Threats A..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the feature if it appear in the colums (done this way so the cell can be re-run)\n",
    "df = df.drop(columns=[col for col in df.columns if col in ['link','authors','headline','short_description','date','link_keywords','author_notes','author_names']])\n",
    "\n",
    "# View Sample\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb007b6-d2dc-4d7c-b402-c82261924282",
   "metadata": {},
   "source": [
    "# <center> -------------------------------------------------------------------- </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d018a1-5899-4858-b61e-56ff7e756afc",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba73be-a3c7-4dd0-9743-1053b30d65e2",
   "metadata": {},
   "source": [
    "#### View categories"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbe5b261-a6fc-45e6-a74b-9aa23c4f4f7d",
   "metadata": {},
   "source": [
    "print(f\"There are {len(df['category'].value_counts())} unique categories including the following:\")\n",
    "px.bar(df['category'].value_counts(), \n",
    "       title='Unique New Categories', \n",
    "       labels = {\"value\": \"Number of Articles\",\"index\": \"Category\"},\n",
    "       width = 800, height = 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d18038-8d52-4e38-8b50-0985920ea7a2",
   "metadata": {},
   "source": [
    "#### View length of texts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f41dda5d-1cf5-4053-82bd-af4c69d0a770",
   "metadata": {},
   "source": [
    "headline_lengths = df['text'].apply(lambda x: len(x))\n",
    "px.histogram(df, \n",
    "             x = headline_lengths, \n",
    "             marginal = 'box', \n",
    "             title = 'Text Lengths',\n",
    "             labels = {'x':'Number of Characters'},\n",
    "             color = 'category',\n",
    "             height = 500, width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c27f96-acfd-433d-b758-6c0159e2e48f",
   "metadata": {},
   "source": [
    "### Author Activity"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fff23eef-0738-4aed-9562-6795cc5908c9",
   "metadata": {},
   "source": [
    "unique_authors_vc = df['author_names'].explode().value_counts()\n",
    "\n",
    "print(f\"There are {len(unique_authors_vc)} unique authors, {unique_authors_vc[0]} ({round(unique_authors_vc[0]/len(unique_authors_vc),2)}%) are unknown.\" )\n",
    "\n",
    "px.bar(unique_authors_vc[1:25], \n",
    "       title='Unique Authors', \n",
    "       labels = {\"value\": \"Number of Articles Written\",\"index\": \"Author\"},\n",
    "       width = 1200, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d17d54-13d9-48d7-85c6-a45df5510091",
   "metadata": {},
   "source": [
    "# <center> -------------------------------------------------------------------- </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28573ff1-d3fe-4385-872c-13d429c28972",
   "metadata": {},
   "source": [
    "# Preprocessing Text Data\n",
    "- Lower all words\n",
    "- Handle misspellings?\n",
    "- Stop words\n",
    "- Stem / Lemmatize text\n",
    "- Tokenization or specialized regex?\n",
    "- Use all words or just most frequent?\n",
    "- Use bigrams, POS taggins, Mutual information Scores?\n",
    "- What sort of vectorization? (Boolean / Count / TF-IDF / Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71728c1f-5d52-4f52-87c6-a34dd89b5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61bb42-eb7b-46c6-a310-d44f96b94738",
   "metadata": {},
   "source": [
    "### Encode Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b7788c7-8872-4c7f-9894-07bddc823cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate label encoder \n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Apply\n",
    "df['class_label'] = le.fit_transform(df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8def016-e2ec-4835-ae6e-2320bd051b35",
   "metadata": {},
   "source": [
    "### Get Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7c31304-040c-4970-9482-818a2a8fb304",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english') + list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da3b01-4919-411b-b7fa-4cb5671c3f9a",
   "metadata": {},
   "source": [
    "### Bag of Words Counts (Count Vectorization)\n",
    "- The count vectorizer performs tokenization on its own (why do we do it also?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd1c25d8-5546-40d3-87a9-80812c967086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def c_vectorize(text):\n",
    "    count_vectorizer = CountVectorizer(stop_words= stopwords_list)\n",
    "\n",
    "    tokens = count_vectorizer.fit_transform(text)\n",
    "\n",
    "    return tokens, count_vectorizer\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"class_label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)\n",
    "\n",
    "X_train_tokenized, count_vectorizer = c_vectorize(X_train)\n",
    "X_test_tokenized = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e9f8b-cb2b-4c41-9ad3-979aa05b48ad",
   "metadata": {},
   "source": [
    "### Model: Multinomial Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87a626-3253-4716-b056-42b89651703c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22321209-30b3-468f-a53a-2ac23e2ccf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tokenized, y_train)\n",
    "y_predicted_counts = clf.predict(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "515a225a-49ac-4053-873c-c649941c468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.954 \n",
      "Precision = 0.954 \n",
      "Recall = 0.954 \n",
      "f1 = 0.954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "\n",
    "    precision = round(precision_score(y_test, y_predicted, average='weighted'),3)\n",
    "    recall = round(recall_score(y_test, y_predicted, average='weighted'),3)\n",
    "    f1 = round(f1_score(y_test, y_predicted, average='weighted'),3)\n",
    "    accuracy = round(accuracy_score(y_test, y_predicted),3)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted_counts)\n",
    "\n",
    "print(f\"Accuracy = {accuracy} \\nPrecision = {precision} \\nRecall = {recall} \\nf1 = {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175f1bd-9846-446d-b6fb-9df38f2f8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_important_features(vectorizer, model, n=5):\n",
    "    index_to_word = {v:k for k,v in vectorizer.vocabulary_.items()}\n",
    "    \n",
    "    # loop for each class\n",
    "    classes = {}\n",
    "    for class_index in range(model.coef_.shape[0]):\n",
    "        word_importances = [(el, index_to_word[i]) for i,el in enumerate(model.coef_[class_index])]\n",
    "        sorted_coeff = sorted(word_importances, key = lambda x : abs(x[0]))\n",
    "        tops = sorted(sorted_coeff[:n], key = lambda x : x[0])\n",
    "        bottom = sorted_coeff[-n:]\n",
    "        classes[class_index] = {\n",
    "            'tops':tops,\n",
    "            'bottom':bottom\n",
    "        }\n",
    "    return classes\n",
    "\n",
    "importance = get_most_important_features(count_vectorizer, clf, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0574b-6988-46c1-96ef-4aef286224ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
