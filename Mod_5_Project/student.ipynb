{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b17f3a-fc40-43d2-b026-798f26014493",
   "metadata": {},
   "source": [
    "# <center> News Classification with NLP </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb09f44-33f4-4938-aaa4-65c3df93b527",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1634b-c53c-4c99-8e6e-f7759bd2856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objects as go\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a02e18-a47b-4179-9c28-fb2bb93cc5d6",
   "metadata": {},
   "source": [
    "### Data\n",
    "- Import JSON file\n",
    "- Limit to top categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ebb1ae-25d6-43d9-9510-54dd2e864b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in json file to DataFrame\n",
    "df = pd.read_json('News_Category_Dataset_v2.json', lines=True)\n",
    "\n",
    "# Get the top categories by article count\n",
    "#top_5_categories = df['category'].value_counts()[:10].index\n",
    "\n",
    "# Limit the DateFrame to the top categories\n",
    "#df = df[df['category'].isin(top_5_categories)]\n",
    "\n",
    "# View Results\n",
    "print(df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd82dfc-6153-4f97-ad75-9007960b828b",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca86a7-4e67-4e77-839e-0a2ffbc6920f",
   "metadata": {},
   "source": [
    "#### Check data types"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e41005e-96ba-4cc5-b7e5-78f99bceae05",
   "metadata": {},
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314368a0-6cfb-4d84-8e6a-53b17873c0f8",
   "metadata": {},
   "source": [
    "#### Check NaNs "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a6edbf1-c01f-4b57-a18d-5e58be8a9fb7",
   "metadata": {},
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601100b7-6574-403b-9df5-b7009c95b3af",
   "metadata": {},
   "source": [
    "#### Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4a10b-d5c2-4811-b945-5ebd596a25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {df.duplicated().sum()} duplicated rows\")\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f\"There are now {df.duplicated().sum()} duplicated rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113bb9ac-6a5a-4abc-ae61-82cc5e5282f2",
   "metadata": {},
   "source": [
    "### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4a424-ddae-4093-af0a-7b42ce4e2952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba9ece-1396-4aaf-b4fe-248728420b19",
   "metadata": {},
   "source": [
    "#### Authors \n",
    "- The `authors` field is a list containing:\n",
    "    - Name(s)\n",
    "    - Titles\n",
    "    - Organizations\n",
    "    - Misc comments\n",
    "- It also contains many NaNs in the form of empty strings\n",
    "- Approach:\n",
    "    - Replace NaNs with 'unknown'\n",
    "    - Extract author names from the field, create new field named `author_names` to be used as a bigram\n",
    "    - Leave the rest of the information in a new field named `author_notes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546711d-3f03-4745-b91c-4eb5ca22438b",
   "metadata": {},
   "source": [
    "### Author Names\n",
    "- Replace missing\n",
    "- Get Names\n",
    "- Clean non-name details\n",
    "- Cast as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f923fa-b7e9-41ea-99b3-1fa83c25f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing authors with 'unknown'\n",
    "df['authors'] = df['authors'].apply(lambda x: x.replace('','unknown') if x == '' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf3c68-2ec9-4b35-b9f8-e3ada87814cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get author names from list\n",
    "# Split, get first, title(), split \n",
    "df['author_names'] = df['authors'].apply(lambda x: x.replace('By','').strip().split(',')[0].lower().split(' And '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5ee91-0e6f-4884-8e8b-351fa63bba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the rest of the authors field without the names into a new field\n",
    "df['author_notes'] = df['authors'].apply(lambda x: ''.join(x.replace('By','').replace('\\n','').replace('Contributor','Contributor ').strip().split(',')[1:]).strip())\n",
    "\n",
    "# Type cast from list to string\n",
    "df['author_notes'] = df['author_notes'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85739996-443e-4d95-8cbc-5eb9ff0cc15c",
   "metadata": {},
   "source": [
    "### Links\n",
    "- The links are not helpful in their current form, need to extract keyworks from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8dd769-3f83-488f-a04e-8b86eab29beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace charaters we want to split on with commas, then split, only get the relevant entries from the resulting list\n",
    "df['link_keywords'] = df['link'].apply(lambda x: x.replace('-',',').replace(\"_\",',').replace(\"entry/\",',').split(',')[1:-2])\n",
    "\n",
    "# Typecast from list to string\n",
    "df['link_keywords'] = df['link_keywords'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# View Sample\n",
    "df['link_keywords'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ff202-4315-4e44-bd04-707dd47962df",
   "metadata": {},
   "source": [
    "### Join all text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df868d-a8fb-49d2-962d-3ff44d3c11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['headline'] + ' ' + df['short_description'] + ' ' + df['link_keywords'] + ' ' + df['author_names'].astype(str) + ' ' + df['author_notes'] + ' ' + df['date'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6ea61-e042-41bd-8c32-79609de50c10",
   "metadata": {},
   "source": [
    "### Drop unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba9bb9-a3b4-4265-b6ed-8871b2cbfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the feature if it appear in the colums (done this way so the cell can be re-run)\n",
    "df = df.drop(columns=[col for col in df.columns if col in ['link','authors','headline','short_description','date','link_keywords','author_notes','author_names']])\n",
    "\n",
    "# View Sample\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb007b6-d2dc-4d7c-b402-c82261924282",
   "metadata": {},
   "source": [
    "# <center> -------------------------------------------------------------------- </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d018a1-5899-4858-b61e-56ff7e756afc",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba73be-a3c7-4dd0-9743-1053b30d65e2",
   "metadata": {},
   "source": [
    "#### View categories"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbe5b261-a6fc-45e6-a74b-9aa23c4f4f7d",
   "metadata": {},
   "source": [
    "print(f\"There are {len(df['category'].value_counts())} unique categories including the following:\")\n",
    "px.bar(df['category'].value_counts(), \n",
    "       title='Unique New Categories', \n",
    "       labels = {\"value\": \"Number of Articles\",\"index\": \"Category\"},\n",
    "       width = 800, height = 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d18038-8d52-4e38-8b50-0985920ea7a2",
   "metadata": {},
   "source": [
    "#### View length of texts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f41dda5d-1cf5-4053-82bd-af4c69d0a770",
   "metadata": {},
   "source": [
    "headline_lengths = df['text'].apply(lambda x: len(x))\n",
    "px.histogram(df, \n",
    "             x = headline_lengths, \n",
    "             marginal = 'box', \n",
    "             title = 'Text Lengths',\n",
    "             labels = {'x':'Number of Characters'},\n",
    "             color = 'category',\n",
    "             height = 500, width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c27f96-acfd-433d-b758-6c0159e2e48f",
   "metadata": {},
   "source": [
    "### Author Activity"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fff23eef-0738-4aed-9562-6795cc5908c9",
   "metadata": {},
   "source": [
    "unique_authors_vc = df['author_names'].explode().value_counts()\n",
    "\n",
    "print(f\"There are {len(unique_authors_vc)} unique authors, {unique_authors_vc[0]} ({round(unique_authors_vc[0]/len(unique_authors_vc),2)}%) are unknown.\" )\n",
    "\n",
    "px.bar(unique_authors_vc[1:25], \n",
    "       title='Unique Authors', \n",
    "       labels = {\"value\": \"Number of Articles Written\",\"index\": \"Author\"},\n",
    "       width = 1200, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d17d54-13d9-48d7-85c6-a45df5510091",
   "metadata": {},
   "source": [
    "# <center> -------------------------------------------------------------------- </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28573ff1-d3fe-4385-872c-13d429c28972",
   "metadata": {},
   "source": [
    "# Preprocessing Text Data\n",
    "- Lower all words\n",
    "- Handle misspellings?\n",
    "- Stop words\n",
    "- Stem / Lemmatize text\n",
    "- Tokenization or specialized regex?\n",
    "- Use all words or just most frequent?\n",
    "- Use bigrams, POS taggins, Mutual information Scores?\n",
    "- What sort of vectorization? (Boolean / Count / TF-IDF / Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71728c1f-5d52-4f52-87c6-a34dd89b5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61bb42-eb7b-46c6-a310-d44f96b94738",
   "metadata": {},
   "source": [
    "### Encode Target Variable / OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7788c7-8872-4c7f-9894-07bddc823cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate label encoder \n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Apply\n",
    "df['class_label'] = le.fit_transform(df['category'])\n",
    "\n",
    "# Create dictionary to map labels to categories\n",
    "label_to_category = dict(df.groupby('class_label')['category'].first())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8def016-e2ec-4835-ae6e-2320bd051b35",
   "metadata": {},
   "source": [
    "### Get Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c31304-040c-4970-9482-818a2a8fb304",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english') + list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c14a8a-2002-41f9-93c7-c58d2ce6b7e9",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755edad4-1701-46ef-bbbf-335613479515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dependent and independent variables\n",
    "X = df[\"text\"]\n",
    "y = df[\"class_label\"]\n",
    "\n",
    "# Perform Test Train Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e976398-5749-4767-b062-2370566137b0",
   "metadata": {},
   "source": [
    "### OHE target for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc2baf-6adb-4303-8d08-fb5694df9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE for netural network\n",
    "y_train_ohe = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da3b01-4919-411b-b7fa-4cb5671c3f9a",
   "metadata": {},
   "source": [
    "### Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c25d8-5546-40d3-87a9-80812c967086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate CountVectorizer with custom list of stop words\n",
    "count_vectorizer = CountVectorizer(stop_words= stopwords_list)\n",
    "\n",
    "# Fit the tokenizer on the training data\n",
    "count_vectorizer.fit(X_train)\n",
    "\n",
    "# Apply the tokenizer to the training and testing data\n",
    "X_train_tokenized = count_vectorizer.transform(X_train)\n",
    "X_test_tokenized = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e9f8b-cb2b-4c41-9ad3-979aa05b48ad",
   "metadata": {},
   "source": [
    "## Model: Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22321209-30b3-468f-a53a-2ac23e2ccf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB_clf = MultinomialNB()\n",
    "MNB_clf.fit(X_train_tokenized, y_train)\n",
    "y_predicted_counts = MNB_clf.predict(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87a626-3253-4716-b056-42b89651703c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a225a-49ac-4053-873c-c649941c468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "\n",
    "    precision = round(precision_score(y_test, y_predicted, average='weighted'),3)\n",
    "    recall = round(recall_score(y_test, y_predicted, average='weighted'),3)\n",
    "    f1 = round(f1_score(y_test, y_predicted, average='weighted'),3)\n",
    "    accuracy = round(accuracy_score(y_test, y_predicted),3)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted_counts)\n",
    "\n",
    "print(f\"Accuracy = {accuracy} \\nPrecision = {precision} \\nRecall = {recall} \\nf1 = {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb0370-57f3-4dd8-8fa6-f6513458070e",
   "metadata": {},
   "source": [
    "## Model: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996917c-12b6-4ee1-a20c-d176252d206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23067729-838a-46e0-8927-533142ff8157",
   "metadata": {},
   "source": [
    "### Creat model and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06355619-ae97-4cbe-8555-1d6a84cf538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d0525-ac0a-4242-946c-d970618aad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Two layers with relu activation\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(103006,)))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# One layer with softmax activation \n",
    "model.add(layers.Dense(41, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf285352-5a66-4d9e-a7bb-6b36af673c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef68727-0ba3-4ca0-bf57-144eee96cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model \n",
    "history = model.fit(X_train_tokenized, y_train_ohe, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
