{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b17f3a-fc40-43d2-b026-798f26014493",
   "metadata": {},
   "source": [
    "# <center> News Classification with NLP and Neural Networks</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb09f44-33f4-4938-aaa4-65c3df93b527",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a1634b-c53c-4c99-8e6e-f7759bd2856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objects as go\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a02e18-a47b-4179-9c28-fb2bb93cc5d6",
   "metadata": {},
   "source": [
    "### Data\n",
    "- Import JSON file\n",
    "- Limit to top categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14ebb1ae-25d6-43d9-9510-54dd2e864b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34886, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_year</th>\n",
       "      <th>genre</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12667</th>\n",
       "      <td>1996</td>\n",
       "      <td>action</td>\n",
       "      <td>A group of terrorists led by Luther (Jeff Kobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31133</th>\n",
       "      <td>2012</td>\n",
       "      <td>drama</td>\n",
       "      <td>Sundarapandian (Sasi Kumar) is the only son of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17853</th>\n",
       "      <td>2010</td>\n",
       "      <td>war</td>\n",
       "      <td>The great film begins with a video log by Elli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21752</th>\n",
       "      <td>1980</td>\n",
       "      <td>drama</td>\n",
       "      <td>The Hounds of Notre Dame is about 36 hours in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22682</th>\n",
       "      <td>2013</td>\n",
       "      <td>romance / drama</td>\n",
       "      <td>After graduation, the girls gathered together ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       release_year            genre  \\\n",
       "12667          1996           action   \n",
       "31133          2012            drama   \n",
       "17853          2010              war   \n",
       "21752          1980            drama   \n",
       "22682          2013  romance / drama   \n",
       "\n",
       "                                                    plot  \n",
       "12667  A group of terrorists led by Luther (Jeff Kobe...  \n",
       "31133  Sundarapandian (Sasi Kumar) is the only son of...  \n",
       "17853  The great film begins with a video log by Elli...  \n",
       "21752  The Hounds of Notre Dame is about 36 hours in ...  \n",
       "22682  After graduation, the girls gathered together ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in json file to DataFrame\n",
    "df = pd.read_csv('wiki_movie_plots_deduped.csv')\n",
    "\n",
    "# Only keep relevant data\n",
    "df = df.drop(columns=['Title','Origin/Ethnicity','Wiki Page','Cast','Director'])\n",
    "\n",
    "# Format column names for sanity\n",
    "df.columns = [i.replace(\" \",\"_\").lower() for i in df.columns]\n",
    "\n",
    "# View Results\n",
    "print(df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd82dfc-6153-4f97-ad75-9007960b828b",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca86a7-4e67-4e77-839e-0a2ffbc6920f",
   "metadata": {},
   "source": [
    "#### Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7cf063e-ea3f-47f8-b8e1-d6f539f41f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34886 entries, 0 to 34885\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   release_year  34886 non-null  int64 \n",
      " 1   genre         34886 non-null  object\n",
      " 2   plot          34886 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 817.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314368a0-6cfb-4d84-8e6a-53b17873c0f8",
   "metadata": {},
   "source": [
    "#### Check NaNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f62f031-4ddf-40f0-926a-2840eeab74e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "release_year    0\n",
       "genre           0\n",
       "plot            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601100b7-6574-403b-9df5-b7009c95b3af",
   "metadata": {},
   "source": [
    "#### Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ee4a10b-d5c2-4811-b945-5ebd596a25c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 138 duplicated rows\n",
      "There are now 0 duplicated rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df.duplicated().sum()} duplicated rows\")\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f\"There are now {df.duplicated().sum()} duplicated rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32d318-0d03-4229-81b9-e818791508f3",
   "metadata": {},
   "source": [
    "### Genre Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b0f9657-adae-4c8a-9de6-9049e8d469dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre'] = df['genre'].apply(lambda x: x.replace(\" \",\",\").replace(\"/\",\",\").replace(\"-\",\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3578e2d-9ae1-4ac3-8c7a-4e547777a7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown             6012\n",
       "drama               5950\n",
       "comedy              4376\n",
       "horror              1160\n",
       "action              1091\n",
       "thriller             964\n",
       "romance              921\n",
       "western              862\n",
       "crime                566\n",
       "adventure            525\n",
       "crime,drama          480\n",
       "romantic,comedy      474\n",
       "musical              466\n",
       "science,fiction      431\n",
       "film,noir            344\n",
       "mystery              310\n",
       "comedy,drama         302\n",
       "war                  273\n",
       "animation            264\n",
       "comedy,,drama        235\n",
       "sci,fi               221\n",
       "family               217\n",
       "fantasy              203\n",
       "animated             195\n",
       "musical,comedy       163\n",
       "biography            136\n",
       "anime                110\n",
       "suspense             104\n",
       "romantic,drama       102\n",
       "action,thriller       93\n",
       "animated,short        91\n",
       "drama,,romance        86\n",
       "social                82\n",
       "historical            77\n",
       "documentary           73\n",
       "action,comedy         72\n",
       "serial                71\n",
       "world,war,ii          70\n",
       "war,drama             70\n",
       "crime,thriller        68\n",
       "romance,drama         66\n",
       "family,drama          66\n",
       "drama,,crime          64\n",
       "comedy,,musical       63\n",
       "historical,drama      61\n",
       "comedy,,romance       60\n",
       "romance,,drama        59\n",
       "biopic                57\n",
       "horror,comedy         53\n",
       "black,comedy          52\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0a9c918-ec04-4ca7-a4c6-e648ce7f86aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for genre in df['genre'].value_counts().keys():\n",
    "    for g in genre.split(\",\"):\n",
    "        if g in df['genre'].value_counts().keys():\n",
    "            df['genre'].map({g:genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "419b794b-c5da-4cd0-a80c-bc8bab351a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown             6012\n",
       "drama               5950\n",
       "comedy              4376\n",
       "horror              1160\n",
       "action              1091\n",
       "thriller             964\n",
       "romance              921\n",
       "western              862\n",
       "crime                566\n",
       "adventure            525\n",
       "crime,drama          480\n",
       "romantic,comedy      474\n",
       "musical              466\n",
       "science,fiction      431\n",
       "film,noir            344\n",
       "mystery              310\n",
       "comedy,drama         302\n",
       "war                  273\n",
       "animation            264\n",
       "comedy,,drama        235\n",
       "sci,fi               221\n",
       "family               217\n",
       "fantasy              203\n",
       "animated             195\n",
       "musical,comedy       163\n",
       "biography            136\n",
       "anime                110\n",
       "suspense             104\n",
       "romantic,drama       102\n",
       "action,thriller       93\n",
       "animated,short        91\n",
       "drama,,romance        86\n",
       "social                82\n",
       "historical            77\n",
       "documentary           73\n",
       "action,comedy         72\n",
       "serial                71\n",
       "world,war,ii          70\n",
       "war,drama             70\n",
       "crime,thriller        68\n",
       "romance,drama         66\n",
       "family,drama          66\n",
       "drama,,crime          64\n",
       "comedy,,musical       63\n",
       "historical,drama      61\n",
       "comedy,,romance       60\n",
       "romance,,drama        59\n",
       "biopic                57\n",
       "horror,comedy         53\n",
       "black,comedy          52\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c5dcf-b5d8-4980-b0a0-ea778bfe374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map aliases\n",
    "genre_alias_dict = {'sci-fi','science fiction'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb007b6-d2dc-4d7c-b402-c82261924282",
   "metadata": {},
   "source": [
    "# <center> -------------------------------------------------------------------- </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d018a1-5899-4858-b61e-56ff7e756afc",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba73be-a3c7-4dd0-9743-1053b30d65e2",
   "metadata": {},
   "source": [
    "#### View categories"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbe5b261-a6fc-45e6-a74b-9aa23c4f4f7d",
   "metadata": {},
   "source": [
    "print(f\"There are {len(df['category'].value_counts())} unique categories including the following:\")\n",
    "px.bar(df['category'].value_counts(), \n",
    "       title='Unique New Categories', \n",
    "       labels = {\"value\": \"Number of Articles\",\"index\": \"Category\"},\n",
    "       width = 800, height = 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d18038-8d52-4e38-8b50-0985920ea7a2",
   "metadata": {},
   "source": [
    "#### View length of texts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f41dda5d-1cf5-4053-82bd-af4c69d0a770",
   "metadata": {},
   "source": [
    "headline_lengths = df['text'].apply(lambda x: len(x))\n",
    "px.histogram(df, \n",
    "             x = headline_lengths, \n",
    "             marginal = 'box', \n",
    "             title = 'Text Lengths',\n",
    "             labels = {'x':'Number of Characters'},\n",
    "             color = 'category',\n",
    "             height = 500, width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c27f96-acfd-433d-b758-6c0159e2e48f",
   "metadata": {},
   "source": [
    "### Author Activity"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fff23eef-0738-4aed-9562-6795cc5908c9",
   "metadata": {},
   "source": [
    "unique_authors_vc = df['author_names'].explode().value_counts()\n",
    "\n",
    "print(f\"There are {len(unique_authors_vc)} unique authors, {unique_authors_vc[0]} ({round(unique_authors_vc[0]/len(unique_authors_vc),2)}%) are unknown.\" )\n",
    "\n",
    "px.bar(unique_authors_vc[1:25], \n",
    "       title='Unique Authors', \n",
    "       labels = {\"value\": \"Number of Articles Written\",\"index\": \"Author\"},\n",
    "       width = 1200, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d17d54-13d9-48d7-85c6-a45df5510091",
   "metadata": {},
   "source": [
    "# <center> -------------------------------------------------------------------- </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28573ff1-d3fe-4385-872c-13d429c28972",
   "metadata": {},
   "source": [
    "# Preprocessing Text Data\n",
    "- Stop words\n",
    "- Stem / Lemmatize text\n",
    "- Tokenization\n",
    "- Use all words or just most frequent?\n",
    "- Use bigrams, POS taggins, Mutual information Scores?\n",
    "- What sort of vectorization? (Boolean / Count / TF-IDF / Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71728c1f-5d52-4f52-87c6-a34dd89b5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61bb42-eb7b-46c6-a310-d44f96b94738",
   "metadata": {},
   "source": [
    "### Encode Target Variable\n",
    "- Assign a unique value to each categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7788c7-8872-4c7f-9894-07bddc823cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate label encoder \n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Label Encode categories\n",
    "df['class_label'] = le.fit_transform(df['category'])\n",
    "\n",
    "# Create dictionary to map labels to categories\n",
    "label_to_category = dict(df.groupby('class_label')['category'].first())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8def016-e2ec-4835-ae6e-2320bd051b35",
   "metadata": {},
   "source": [
    "### Get Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c31304-040c-4970-9482-818a2a8fb304",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english') + list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c14a8a-2002-41f9-93c7-c58d2ce6b7e9",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755edad4-1701-46ef-bbbf-335613479515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dependent and independent variables\n",
    "X = df[\"text\"]\n",
    "y = df[\"class_label\"]\n",
    "\n",
    "# Perform Test Train Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da3b01-4919-411b-b7fa-4cb5671c3f9a",
   "metadata": {},
   "source": [
    "### Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c25d8-5546-40d3-87a9-80812c967086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate CountVectorizer with custom list of stop words\n",
    "count_vectorizer = CountVectorizer(stop_words= stopwords_list)\n",
    "\n",
    "# Fit the tokenizer on the training data\n",
    "count_vectorizer.fit(X_train)\n",
    "\n",
    "# Apply the tokenizer to the training and testing data\n",
    "X_train_counts = count_vectorizer.transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "X_val_counts = count_vectorizer.transform(X_val)\n",
    "\n",
    "# View Results\n",
    "print(f'There are {X_train_counts.shape[0]} observations and {X_train_counts.shape[1]} features')\n",
    "pd.DataFrame(data= X_val_counts[:5].toarray(), columns = count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb0370-57f3-4dd8-8fa6-f6513458070e",
   "metadata": {},
   "source": [
    "## Model: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996917c-12b6-4ee1-a20c-d176252d206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f333256-39d7-470a-8e27-7ba35151f19a",
   "metadata": {},
   "source": [
    "### OHE target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1164e5-684c-44e0-98b6-dd064ff52aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# OHE for netural network\n",
    "y_train_ohe = to_categorical(y_train)\n",
    "y_val_ohe = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23067729-838a-46e0-8927-533142ff8157",
   "metadata": {},
   "source": [
    "### Create model\n",
    "- Fully connected (dense) layer network with relu activation\n",
    "- 2 hidden layers with 50 units in 1st and 25 in second\n",
    "- Softmax classifier for nulticlass problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d0525-ac0a-4242-946c-d970618aad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# One layer with softmax activation \n",
    "model.add(layers.Dense(41, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d315a6b-bb33-4caf-ac75-ab889cab5673",
   "metadata": {},
   "source": [
    "### Compiling the model\n",
    "- Loss function = categorical crossentropy\n",
    "- Optimizer = stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf285352-5a66-4d9e-a7bb-6b36af673c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef68727-0ba3-4ca0-bf57-144eee96cadb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model \n",
    "n_epochs = 10\n",
    "history = model.fit(X_train_counts, y_train_ohe, epochs= n_epochs, validation_data = (X_val_counts, y_val_ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca0c7c-9b25-41e3-bcac-3cf7c61aca01",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99933323-5e79-4b08-b536-84da04aa0b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "def get_model_metrics(actuals, predictions, full_report = False, plot = False):  \n",
    "\n",
    "    predictions_bool = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision = round(precision_score(actuals, predictions_bool, average='weighted'),3)\n",
    "    recall = round(recall_score(actuals, predictions_bool, average='weighted'),3)\n",
    "    f1 = round(f1_score(actuals, predictions_bool, average='weighted'),3)\n",
    "    accuracy = round(accuracy_score(actuals, predictions_bool),3)\n",
    "    \n",
    "    if full_report == False:\n",
    "        print(f\"Accuracy = {accuracy} \\nPrecision = {precision} \\nRecall = {recall} \\nf1 = {f1}\")\n",
    "    else:\n",
    "        print(classification_report(actuals, predictions_bool))\n",
    "    if plot == True:\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=[i for i in range(20)], y=history.history['acc'],\n",
    "                            mode='lines+markers', name='Train Accuracy'))\n",
    "        fig.add_trace(go.Scatter(x=[i for i in range(20)], y=history.history['val_acc'],\n",
    "                            mode='lines+markers', name='Validation Accuracy'))\n",
    "\n",
    "        fig.update_layout(height= 500, width= 700)\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a342fc8-3e01-402f-9e72-dcb1a2f0e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_metrics(y_val, model.predict(X_val_counts), full_report = 0, plot = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7788a2d-bb6b-4f90-b552-514e7a0eddf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
